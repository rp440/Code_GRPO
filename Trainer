import time
import yaml
import copy
import random
import shutil
from tqdm import tqdm 
import torch
from torch.utils.data import DataLoader, Subset
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import multiprocessing as mp
from functools import partial

class Trainer():
    # ... existing code ...
    
    def _generate_single_sample(self, args):
        """Helper function to generate a single sample - can be used by multiprocessing"""
        R_limit, prob, coefficients, S_size, T, save_type = args
        
        R = random.randint(1, R_limit)
        for _ in range(10000):
            sample = np.zeros((S_size, S_size, S_size), dtype=np.int32)
            states = []        
            actions = []
            rewards = []                
            for r in range(1, (R+1)):
                ct = 0
                while True:
                    u = np.random.choice(coefficients, size=(S_size,), p=prob, replace=True)
                    v = np.random.choice(coefficients, size=(S_size,), p=prob, replace=True)
                    w = np.random.choice(coefficients, size=(S_size,), p=prob, replace=True)
                    ct += 1
                    if not is_zero_tensor(outer(u, v, w)):
                        break
                    if ct > 100000:
                        raise Exception("Oh my god...")
                sample = sample + outer(u, v, w)
                action = np.stack([u, v, w], axis=0)
                actions.append(canonicalize_action(action))
                states.append(sample.copy())
                rewards.append(-r)
            
            # Check redundancy.
            red_flag = False
            for (i, j) in [[0,1], [1,2], [2,0]]:
                _mat = np.zeros((S_size ** 2, R), dtype=np.int32)
                for idx, action in enumerate(actions):
                    _mat[:, idx] = np.outer(action[i], action[j]).reshape((-1,))
                if np.linalg.matrix_rank(_mat) < R:
                    red_flag = True
                    break
            
            if red_flag:
                continue
            break
            
        # Reformulate the results.
        if save_type == "tuple":
            states.reverse(); actions.reverse(); rewards.reverse()
            actions_tensor = [action2tensor(action) for action in actions]
            result = []
            for idx, state in enumerate(states):
                tensors = np.zeros((T, S_size, S_size, S_size), dtype=np.int32)
                tensors[0] = state            # state.
                if idx != 0:
                    # History actions.
                    tensors[1:(idx+1)] = np.stack(reversed(actions_tensor[max(idx-(T-1), 0):idx]), axis=0)        
                scalars = np.array([idx, idx, idx])     #FIXME: Havn't decided the scalars.
                
                cur_state = [tensors, scalars]
                action = actions[idx]
                reward = rewards[idx]
                result.append([cur_state, action, reward])
            return result
        else:
            traj = [states, actions, rewards]          # Note: Synthesis order...
            return traj

    def generate_synthetic_examples(self,
                                    prob=[.8, .1, .1],
                                    samples_n=10000,
                                    R_limit=12,
                                    save_path=None,
                                    save_type="traj",
                                    num_workers=None) -> list:
        '''
        生成人工合成的Tensor examples
        返回: results
        '''
        assert save_type in ["traj", "tuple"]
        
        if num_workers is None:
            num_workers = mp.cpu_count()
        
        # Prepare arguments for each worker
        args_list = [(R_limit, prob, self.coefficients, self.S_size, self.T, save_type) 
                     for _ in range(samples_n)]
        
        total_results = []
        
        # Use multiprocessing to generate samples in parallel
        with mp.Pool(processes=num_workers) as pool:
            results = list(tqdm(pool.imap(self._generate_single_sample, args_list), 
                               total=samples_n, desc="Generating synthetic examples"))
            
            # Flatten results if save_type is "tuple"
            if save_type == "tuple":
                for result in results:
                    total_results.extend(result)
            else:
                total_results = results
                
        if save_path is not None:
            np.save(save_path, np.array(total_results, dtype=object))
            
        return total_results

    # ... rest of existing code ... 